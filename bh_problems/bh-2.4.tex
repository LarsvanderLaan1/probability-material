\input{header.tex}
\begin{exercise}[BH.2.4]
\setcounter{theorem}{3}
\begin{solution}~
	\begin{enumerate}
		\item We are given in the question that
		\begin{align*}
			P(R|K) &= 1,\\
			P(R|K^{C})&=\frac{1}{n},\\
			P(K) &= p.
		\end{align*}
		What is $P(K|R)$? What do you think, maybe Bayes' rule?
		\begin{align*}
			P(K|R)& = \frac{P(R|K)P(K)}{P(R|K)P(K)+P(R|K^{C})P(K^{C})}\\
			&=\frac{p}{p + \frac{1-p}{n}}\\
			& = \frac{n}{(n-1)p+1}p.
		\end{align*}
		\item  From (a)
		\begin{align*}
			P(K|R) = \frac{n}{(n-1)p+1}p.
		\end{align*}
		Since $\frac{n}{(n-1)p+1}\geq \frac{n}{(n-1)+1} = 1$, we have $P(K|R)\geq p$. Given the evidence that Fred has the right answer you update your belief that he actually knows the answer upwards. Of course, if $p=0$, then $P(K)=P(K|R)=0$. If we know that Fred can never know the answer, then any evidence that he got an answer right must be interpreted as due to random chance. (Thank Quinten Huisman for pointing this case out) Or if $p=1$, then Fred always knows the answer, so event $R$ does not update the probability of the event $K$ either. 
	\end{enumerate}
\end{solution}
\end{exercise}
\input{trailer.tex}
